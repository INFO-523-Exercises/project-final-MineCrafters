{
  "hash": "483923c7dcf61717cf0b59762cdf2d1a",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Brick-Metrics\nsubtitle: Building Precision in Predicting USA Home Prices\nauthor: MineCrafters\ncode-fold: true\n---\n\n## Abstract\n\nThis project is aimed at the development and evaluation of regression models for predicting housing prices using a dataset titled 'USA_Housing.csv.' The overarching goal is to construct robust and accurate models through the application of various machine learning algorithms. The project follows a systematic workflow, encompassing data exploration, feature engineering, model training, hyperparameter tuning, and comprehensive performance evaluation.\n\nThe initial phase involves the importing of essential Python libraries, such as NumPy, Pandas, Matplotlib, Seaborn, and scikit-learn, conducting an in-depth exploratory data analysis (EDA), unveiling insights into data distributions, correlations, and potential preprocessing requirements. Visualizations, including histograms, bar plots, and heatmaps, aid in understanding the dataset's characteristics.\n\nFurther, the project employs a diverse set of regression models, including Decision Tree Regressor, Random Forest Regressor, XGBoost Regressor, Support Vector Regression (SVR), and Elastic Net Regression. Thus, the project provides a practical implementation of regression modeling for housing price prediction\n\n\n## Introduction\n\nIn the dynamic landscape of the US real estate market, predicting house prices is paramount for informed decision-making. This project employs cutting-edge machine learning techniques to unravel the intricate patterns and factors influencing housing values. By leveraging vast datasets, our aim is to develop a robust predictive model.\n\n\n## Question\n\nHow accurately can the housing prices in the US be predicted?\n\n## Approach\n\nInitially, the 'USA_Housing.csv' dataset was loaded, and a meticulous Exploratory Data Analysis (EDA) was performed. The intricacies of data types, null values, and statistical summaries were unveiled, providing critical insights into the dataset's characteristics. Then, it was split into training and testing sets to develop the machine learning models. Further, the regression were developed and were evaluated on the basis of R2 score.\n\n## Analysis\n\nThis section presents the complete process of the developing the Decision Tree, Random Forest, XGBoost Regressor, Support Vector Regression, and Elastic Net Regression techniques.\n\n::: {#f54dd02a .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost as xgb\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\n```\n:::\n\n\n::: {#535a3b4a .cell execution_count=2}\n``` {.python .cell-code}\n# Reading csv file\ndata = pd.read_csv('USA_Housing.csv')\ndata\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Avg. Area Income</th>\n      <th>Avg. Area House Age</th>\n      <th>Avg. Area Number of Rooms</th>\n      <th>Avg. Area Number of Bedrooms</th>\n      <th>Area Population</th>\n      <th>Price</th>\n      <th>Address</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>79545.458574</td>\n      <td>5.682861</td>\n      <td>7.009188</td>\n      <td>4.09</td>\n      <td>23086.800503</td>\n      <td>1.059034e+06</td>\n      <td>208 Michael Ferry Apt. 674\\r\\nLaurabury, NE 37...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>79248.642455</td>\n      <td>6.002900</td>\n      <td>6.730821</td>\n      <td>3.09</td>\n      <td>40173.072174</td>\n      <td>1.505891e+06</td>\n      <td>188 Johnson Views Suite 079\\r\\nLake Kathleen, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>61287.067179</td>\n      <td>5.865890</td>\n      <td>8.512727</td>\n      <td>5.13</td>\n      <td>36882.159400</td>\n      <td>1.058988e+06</td>\n      <td>9127 Elizabeth Stravenue\\r\\nDanieltown, WI 064...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>63345.240046</td>\n      <td>7.188236</td>\n      <td>5.586729</td>\n      <td>3.26</td>\n      <td>34310.242831</td>\n      <td>1.260617e+06</td>\n      <td>USS Barnett\\r\\nFPO AP 44820</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>59982.197226</td>\n      <td>5.040555</td>\n      <td>7.839388</td>\n      <td>4.23</td>\n      <td>26354.109472</td>\n      <td>6.309435e+05</td>\n      <td>USNS Raymond\\r\\nFPO AE 09386</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>60567.944140</td>\n      <td>7.830362</td>\n      <td>6.137356</td>\n      <td>3.46</td>\n      <td>22837.361035</td>\n      <td>1.060194e+06</td>\n      <td>USNS Williams\\r\\nFPO AP 30153-7653</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>78491.275435</td>\n      <td>6.999135</td>\n      <td>6.576763</td>\n      <td>4.02</td>\n      <td>25616.115489</td>\n      <td>1.482618e+06</td>\n      <td>PSC 9258, Box 8489\\r\\nAPO AA 42991-3352</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>63390.686886</td>\n      <td>7.250591</td>\n      <td>4.805081</td>\n      <td>2.13</td>\n      <td>33266.145490</td>\n      <td>1.030730e+06</td>\n      <td>4215 Tracy Garden Suite 076\\r\\nJoshualand, VA ...</td>\n    </tr>\n    <tr>\n      <th>4998</th>\n      <td>68001.331235</td>\n      <td>5.534388</td>\n      <td>7.130144</td>\n      <td>5.44</td>\n      <td>42625.620156</td>\n      <td>1.198657e+06</td>\n      <td>USS Wallace\\r\\nFPO AE 73316</td>\n    </tr>\n    <tr>\n      <th>4999</th>\n      <td>65510.581804</td>\n      <td>5.992305</td>\n      <td>6.792336</td>\n      <td>4.07</td>\n      <td>46501.283803</td>\n      <td>1.298950e+06</td>\n      <td>37778 George Ridges Apt. 509\\r\\nEast Holly, NV...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows Ã— 7 columns</p>\n</div>\n```\n:::\n:::\n\n\n### Exploratory Data Analysis\n\n::: {#748da57c .cell execution_count=3}\n``` {.python .cell-code}\ndata.info()#print a concise summary of a DataFrame\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5000 entries, 0 to 4999\nData columns (total 7 columns):\n #   Column                        Non-Null Count  Dtype  \n---  ------                        --------------  -----  \n 0   Avg. Area Income              5000 non-null   float64\n 1   Avg. Area House Age           5000 non-null   float64\n 2   Avg. Area Number of Rooms     5000 non-null   float64\n 3   Avg. Area Number of Bedrooms  5000 non-null   float64\n 4   Area Population               5000 non-null   float64\n 5   Price                         5000 non-null   float64\n 6   Address                       5000 non-null   object \ndtypes: float64(6), object(1)\nmemory usage: 273.6+ KB\n```\n:::\n:::\n\n\n::: {#812eeb1c .cell execution_count=4}\n``` {.python .cell-code}\n# Checking null values\ndata.isnull().sum()\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\nAvg. Area Income                0\nAvg. Area House Age             0\nAvg. Area Number of Rooms       0\nAvg. Area Number of Bedrooms    0\nArea Population                 0\nPrice                           0\nAddress                         0\ndtype: int64\n```\n:::\n:::\n\n\n::: {#97475ae9 .cell execution_count=5}\n``` {.python .cell-code}\ndata.describe()# Generate descriptive statistics summarizing central tendency, dispersion, and shape of dataset's distribution.\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Avg. Area Income</th>\n      <th>Avg. Area House Age</th>\n      <th>Avg. Area Number of Rooms</th>\n      <th>Avg. Area Number of Bedrooms</th>\n      <th>Area Population</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5000.000000</td>\n      <td>5000.000000</td>\n      <td>5000.000000</td>\n      <td>5000.000000</td>\n      <td>5000.000000</td>\n      <td>5.000000e+03</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>68583.108984</td>\n      <td>5.977222</td>\n      <td>6.987792</td>\n      <td>3.981330</td>\n      <td>36163.516039</td>\n      <td>1.232073e+06</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>10657.991214</td>\n      <td>0.991456</td>\n      <td>1.005833</td>\n      <td>1.234137</td>\n      <td>9925.650114</td>\n      <td>3.531176e+05</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>17796.631190</td>\n      <td>2.644304</td>\n      <td>3.236194</td>\n      <td>2.000000</td>\n      <td>172.610686</td>\n      <td>1.593866e+04</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>61480.562388</td>\n      <td>5.322283</td>\n      <td>6.299250</td>\n      <td>3.140000</td>\n      <td>29403.928702</td>\n      <td>9.975771e+05</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>68804.286404</td>\n      <td>5.970429</td>\n      <td>7.002902</td>\n      <td>4.050000</td>\n      <td>36199.406689</td>\n      <td>1.232669e+06</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>75783.338666</td>\n      <td>6.650808</td>\n      <td>7.665871</td>\n      <td>4.490000</td>\n      <td>42861.290769</td>\n      <td>1.471210e+06</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>107701.748378</td>\n      <td>9.519088</td>\n      <td>10.759588</td>\n      <td>6.500000</td>\n      <td>69621.713378</td>\n      <td>2.469066e+06</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#7856f6e7 .cell execution_count=6}\n``` {.python .cell-code}\n# Data Claening\ndf = pd.DataFrame()\ndf['Income'] = data['Avg. Area Income'].round(2)# Round 'Avg. Area Income' to 2 decimal places and store in 'Income'.\ndf['House Age'] = data['Avg. Area House Age'].apply(int)# Converting 'Avg. Area House Age' to integers and adding it to 'df' as 'House Age'.\ndf['No. of Rooms'] = data['Avg. Area Number of Rooms'].apply(int)# Converting 'Avg. Area Number of Rooms' to integers and adding it to 'df' as 'No. of Rooms'.\ndf['No. of Bedrooms'] = data['Avg. Area Number of Bedrooms'].apply(int)# Converting 'Avg. Area Number of Bedrooms' to integers and adding it to 'df' as 'No. of Bedrooms'.\ndf['Population'] = data['Area Population'].apply(int)# Converting 'Area Population' to integers and adding it to 'df' as 'Population'.\ndf['Price'] = data['Price'].apply(int)# Converting 'Price' to integers and adding it to 'df' as 'Price'.\n```\n:::\n\n\n::: {#d11b0a10 .cell execution_count=7}\n``` {.python .cell-code}\nsns.displot(data['Avg. Area Number of Bedrooms'], kde=False, bins=40)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\Jithin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\axisgrid.py:123: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](MineCrafters_files/figure-html/cell-8-output-2.png){width=470 height=470}\n:::\n:::\n\n\n::: {#71629c6e .cell execution_count=8}\n``` {.python .cell-code}\n# Price plot\nplt.figure(figsize = (12, 6), dpi = 200)\nsns.distplot(data.Price)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\Jithin\\AppData\\Local\\Temp\\ipykernel_28276\\3496450648.py:3: UserWarning: \n\n`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n\nPlease adapt your code to use either `displot` (a figure-level function with\nsimilar flexibility) or `histplot` (an axes-level function for histograms).\n\nFor a guide to updating your code to use the new functions, please see\nhttps://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n\n  sns.distplot(data.Price)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](MineCrafters_files/figure-html/cell-9-output-2.png){}\n:::\n:::\n\n\n::: {#c6e7c3fb .cell execution_count=9}\n``` {.python .cell-code}\n# Price wrt Income\nplt.figure(figsize = (12, 6), dpi = 200)\nsns.lineplot(x = 'Income', y = 'Price', data = df)\n```\n\n::: {.cell-output .cell-output-display}\n![](MineCrafters_files/figure-html/cell-10-output-1.png){}\n:::\n:::\n\n\n::: {#04f7081f .cell execution_count=10}\n``` {.python .cell-code}\n# Price wrt House Age\nplt.figure(figsize = (12, 6), dpi = 200)\nsns.barplot(x = 'House Age', y = 'Price', data = df, ci = None)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\Jithin\\AppData\\Local\\Temp\\ipykernel_28276\\1414414798.py:3: FutureWarning: \n\nThe `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n\n  sns.barplot(x = 'House Age', y = 'Price', data = df, ci = None)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](MineCrafters_files/figure-html/cell-11-output-2.png){}\n:::\n:::\n\n\n::: {#2f541327 .cell execution_count=11}\n``` {.python .cell-code}\n# Price wrt No. of Rooms\nplt.figure(figsize = (12, 6), dpi = 200)\nsns.lineplot(x = 'No. of Rooms', y = 'Price', data = df)\n```\n\n::: {.cell-output .cell-output-display}\n![](MineCrafters_files/figure-html/cell-12-output-1.png){}\n:::\n:::\n\n\n::: {#646f6589 .cell execution_count=12}\n``` {.python .cell-code}\n# Price wrt No. of Bedrooms\nplt.figure(figsize = (12, 6), dpi = 200)\nsns.barplot(x = 'No. of Bedrooms', y = 'Price', data = df, ci = None)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\Jithin\\AppData\\Local\\Temp\\ipykernel_28276\\139840174.py:3: FutureWarning: \n\nThe `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n\n  sns.barplot(x = 'No. of Bedrooms', y = 'Price', data = df, ci = None)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](MineCrafters_files/figure-html/cell-13-output-2.png){}\n:::\n:::\n\n\n::: {#be4b7e93 .cell execution_count=13}\n``` {.python .cell-code}\n# Price wrt Population\nplt.figure(figsize = (12, 6), dpi = 200)\nsns.scatterplot(x = 'Population', y = 'Price', data = df)\n```\n\n::: {.cell-output .cell-output-display}\n![](MineCrafters_files/figure-html/cell-14-output-1.png){}\n:::\n:::\n\n\n::: {#7f7ccbd5 .cell execution_count=14}\n``` {.python .cell-code}\ndef categorize_house_age(df):\n    max_age = df['Avg. Area House Age'].max()\n    bins = [0, 5, 10, max_age]\n    labels = ['New', 'Mid-Age', 'Old']\n    if max_age <= 10:  # Adjusting bins if max age is less than or equal to 10\n        bins = [0, max_age / 3, 2 * max_age / 3, max_age]\n    df['House_Age_Category'] = pd.cut(df['Avg. Area House Age'], bins=bins, labels=labels, include_lowest=True)\n    return df\n\ndata = categorize_house_age(data)\n```\n:::\n\n\n::: {#46c845d3 .cell execution_count=15}\n``` {.python .cell-code}\n# Pairplot segmented by a new categorical feature (if applicable)\nsns.pairplot(data, hue='House_Age_Category')\nplt.show()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\Jithin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\axisgrid.py:123: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](MineCrafters_files/figure-html/cell-16-output-2.png){width=1583 height=1417}\n:::\n:::\n\n\n::: {#0bc1d196 .cell execution_count=16}\n``` {.python .cell-code}\ndata\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Avg. Area Income</th>\n      <th>Avg. Area House Age</th>\n      <th>Avg. Area Number of Rooms</th>\n      <th>Avg. Area Number of Bedrooms</th>\n      <th>Area Population</th>\n      <th>Price</th>\n      <th>Address</th>\n      <th>House_Age_Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>79545.458574</td>\n      <td>5.682861</td>\n      <td>7.009188</td>\n      <td>4.09</td>\n      <td>23086.800503</td>\n      <td>1.059034e+06</td>\n      <td>208 Michael Ferry Apt. 674\\r\\nLaurabury, NE 37...</td>\n      <td>Mid-Age</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>79248.642455</td>\n      <td>6.002900</td>\n      <td>6.730821</td>\n      <td>3.09</td>\n      <td>40173.072174</td>\n      <td>1.505891e+06</td>\n      <td>188 Johnson Views Suite 079\\r\\nLake Kathleen, ...</td>\n      <td>Mid-Age</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>61287.067179</td>\n      <td>5.865890</td>\n      <td>8.512727</td>\n      <td>5.13</td>\n      <td>36882.159400</td>\n      <td>1.058988e+06</td>\n      <td>9127 Elizabeth Stravenue\\r\\nDanieltown, WI 064...</td>\n      <td>Mid-Age</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>63345.240046</td>\n      <td>7.188236</td>\n      <td>5.586729</td>\n      <td>3.26</td>\n      <td>34310.242831</td>\n      <td>1.260617e+06</td>\n      <td>USS Barnett\\r\\nFPO AP 44820</td>\n      <td>Old</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>59982.197226</td>\n      <td>5.040555</td>\n      <td>7.839388</td>\n      <td>4.23</td>\n      <td>26354.109472</td>\n      <td>6.309435e+05</td>\n      <td>USNS Raymond\\r\\nFPO AE 09386</td>\n      <td>Mid-Age</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>60567.944140</td>\n      <td>7.830362</td>\n      <td>6.137356</td>\n      <td>3.46</td>\n      <td>22837.361035</td>\n      <td>1.060194e+06</td>\n      <td>USNS Williams\\r\\nFPO AP 30153-7653</td>\n      <td>Old</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>78491.275435</td>\n      <td>6.999135</td>\n      <td>6.576763</td>\n      <td>4.02</td>\n      <td>25616.115489</td>\n      <td>1.482618e+06</td>\n      <td>PSC 9258, Box 8489\\r\\nAPO AA 42991-3352</td>\n      <td>Old</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>63390.686886</td>\n      <td>7.250591</td>\n      <td>4.805081</td>\n      <td>2.13</td>\n      <td>33266.145490</td>\n      <td>1.030730e+06</td>\n      <td>4215 Tracy Garden Suite 076\\r\\nJoshualand, VA ...</td>\n      <td>Old</td>\n    </tr>\n    <tr>\n      <th>4998</th>\n      <td>68001.331235</td>\n      <td>5.534388</td>\n      <td>7.130144</td>\n      <td>5.44</td>\n      <td>42625.620156</td>\n      <td>1.198657e+06</td>\n      <td>USS Wallace\\r\\nFPO AE 73316</td>\n      <td>Mid-Age</td>\n    </tr>\n    <tr>\n      <th>4999</th>\n      <td>65510.581804</td>\n      <td>5.992305</td>\n      <td>6.792336</td>\n      <td>4.07</td>\n      <td>46501.283803</td>\n      <td>1.298950e+06</td>\n      <td>37778 George Ridges Apt. 509\\r\\nEast Holly, NV...</td>\n      <td>Mid-Age</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows Ã— 8 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {#56632f8b .cell execution_count=17}\n``` {.python .cell-code}\n# Boxplot for Prices across different House Age Categories\nsns.barplot(x='House_Age_Category', y='Price', data=data)\nplt.title('House Prices across Age Categories')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](MineCrafters_files/figure-html/cell-18-output-1.png){width=589 height=449}\n:::\n:::\n\n\n::: {#3b78e6be .cell execution_count=18}\n``` {.python .cell-code}\n# One-Hot Encoding for categorical variables\ndata = pd.get_dummies(data, columns=['House_Age_Category'])\n```\n:::\n\n\n::: {#29cf4120 .cell execution_count=19}\n``` {.python .cell-code}\ndata\n```\n\n::: {.cell-output .cell-output-display execution_count=19}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Avg. Area Income</th>\n      <th>Avg. Area House Age</th>\n      <th>Avg. Area Number of Rooms</th>\n      <th>Avg. Area Number of Bedrooms</th>\n      <th>Area Population</th>\n      <th>Price</th>\n      <th>Address</th>\n      <th>House_Age_Category_New</th>\n      <th>House_Age_Category_Mid-Age</th>\n      <th>House_Age_Category_Old</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>79545.458574</td>\n      <td>5.682861</td>\n      <td>7.009188</td>\n      <td>4.09</td>\n      <td>23086.800503</td>\n      <td>1.059034e+06</td>\n      <td>208 Michael Ferry Apt. 674\\r\\nLaurabury, NE 37...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>79248.642455</td>\n      <td>6.002900</td>\n      <td>6.730821</td>\n      <td>3.09</td>\n      <td>40173.072174</td>\n      <td>1.505891e+06</td>\n      <td>188 Johnson Views Suite 079\\r\\nLake Kathleen, ...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>61287.067179</td>\n      <td>5.865890</td>\n      <td>8.512727</td>\n      <td>5.13</td>\n      <td>36882.159400</td>\n      <td>1.058988e+06</td>\n      <td>9127 Elizabeth Stravenue\\r\\nDanieltown, WI 064...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>63345.240046</td>\n      <td>7.188236</td>\n      <td>5.586729</td>\n      <td>3.26</td>\n      <td>34310.242831</td>\n      <td>1.260617e+06</td>\n      <td>USS Barnett\\r\\nFPO AP 44820</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>59982.197226</td>\n      <td>5.040555</td>\n      <td>7.839388</td>\n      <td>4.23</td>\n      <td>26354.109472</td>\n      <td>6.309435e+05</td>\n      <td>USNS Raymond\\r\\nFPO AE 09386</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>60567.944140</td>\n      <td>7.830362</td>\n      <td>6.137356</td>\n      <td>3.46</td>\n      <td>22837.361035</td>\n      <td>1.060194e+06</td>\n      <td>USNS Williams\\r\\nFPO AP 30153-7653</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>78491.275435</td>\n      <td>6.999135</td>\n      <td>6.576763</td>\n      <td>4.02</td>\n      <td>25616.115489</td>\n      <td>1.482618e+06</td>\n      <td>PSC 9258, Box 8489\\r\\nAPO AA 42991-3352</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>63390.686886</td>\n      <td>7.250591</td>\n      <td>4.805081</td>\n      <td>2.13</td>\n      <td>33266.145490</td>\n      <td>1.030730e+06</td>\n      <td>4215 Tracy Garden Suite 076\\r\\nJoshualand, VA ...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4998</th>\n      <td>68001.331235</td>\n      <td>5.534388</td>\n      <td>7.130144</td>\n      <td>5.44</td>\n      <td>42625.620156</td>\n      <td>1.198657e+06</td>\n      <td>USS Wallace\\r\\nFPO AE 73316</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4999</th>\n      <td>65510.581804</td>\n      <td>5.992305</td>\n      <td>6.792336</td>\n      <td>4.07</td>\n      <td>46501.283803</td>\n      <td>1.298950e+06</td>\n      <td>37778 George Ridges Apt. 509\\r\\nEast Holly, NV...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows Ã— 10 columns</p>\n</div>\n```\n:::\n:::\n\n\n### Setting Target and Variable and Train Test Split\n\n::: {#4485c007 .cell execution_count=20}\n``` {.python .cell-code}\n# Selecting features and target variable\nX = data.drop(['Price', 'Address'], axis=1)\ny = data['Price']\n```\n:::\n\n\n::: {#01c9d149 .cell execution_count=21}\n``` {.python .cell-code}\n# Splitting the dataset into training and testing sets\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n```\n:::\n\n\n### Support Vector Regression\n\n::: {#e5e404eb .cell execution_count=22}\n``` {.python .cell-code}\npip install --upgrade tensorflow\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRequirement already satisfied: tensorflow in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.15.0)\nRequirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.15.0)\nRequirement already satisfied: absl-py>=1.0.0 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\nRequirement already satisfied: astunparse>=1.6.0 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.25.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\nRequirement already satisfied: packaging in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\nRequirement already satisfied: setuptools in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (65.5.0)\nRequirement already satisfied: six>=1.12.0 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.8.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.58.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\nRequirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.25.2)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.1.0)\nRequirement already satisfied: markdown>=2.6.8 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.5.1)\nRequirement already satisfied: requests<3,>=2.21.0 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.0.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.7.22)\nRequirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in c:\\users\\jithin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\nNote: you may need to restart the kernel to use updated packages.\n```\n:::\n:::\n\n\n::: {#e0395beb .cell execution_count=23}\n``` {.python .cell-code}\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWARNING:tensorflow:From C:\\Users\\Jithin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n\n```\n:::\n:::\n\n\n### Neural Network\n\n::: {#74ae9db6 .cell execution_count=24}\n``` {.python .cell-code}\n# Without Hyperparameter tuning\n# Data preprocessing: Standardize the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Neural network model architecture\nmodel = Sequential()\nmodel.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(1))  # Output layer for regression\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# Train the model\nhistory = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n\n# Evaluate the model on test data\npredictions = model.predict(X_test_scaled)\nmse = mean_squared_error(y_test, predictions)\nr2 = r2_score(y_test, predictions)\nprint(f'Mean Squared Error: {mse}')\nprint(f'R-squared: {r2}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWARNING:tensorflow:From C:\\Users\\Jithin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nWARNING:tensorflow:From C:\\Users\\Jithin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\nWARNING:tensorflow:From C:\\Users\\Jithin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n\n\r 1/32 [..............................] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 504us/step\nMean Squared Error: 30448872247.9731\nR-squared: 0.7525134927161543\n```\n:::\n:::\n\n\n::: {#1c6e3be9 .cell execution_count=25}\n``` {.python .cell-code}\n# Define the function to create and train the Keras model\ndef create_model(neurons=64, activation='relu', optimizer='adam'):\n    model = Sequential()\n    model.add(Dense(neurons, activation=activation, input_shape=(X_train.shape[1],)))\n    model.add(Dense(32, activation=activation))\n    model.add(Dense(1))  # Output layer for regression\n    model.compile(optimizer=optimizer, loss='mean_squared_error')\n    return model\n\n# Define hyperparameters to search through\nneurons_list = [32, 64, 128]\nactivation_list = ['relu', 'tanh']\noptimizer_list = ['adam', 'rmsprop']\nbatch_size_list = [32, 64]\nepochs_list = [50, 100]\n\nbest_score = float('inf')\nbest_params = {}\n\n# Iterate through different hyperparameter combinations\nfor neurons in neurons_list:\n    for activation in activation_list:\n        for optimizer in optimizer_list:\n            for batch_size in batch_size_list:\n                for epochs in epochs_list:\n                    # Create and train the model\n                    model = create_model(neurons=neurons, activation=activation, optimizer=optimizer)\n                    model.fit(X_train_scaled, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n                    \n                    # Evaluate the model\n                    predictions = model.predict(X_test_scaled)\n                    mse = mean_squared_error(y_test, predictions)\n                    \n                    # Update best parameters if a better model is found\n                    if mse < best_score:\n                        best_score = mse\n                        best_params = {\n                            'neurons': neurons,\n                            'activation': activation,\n                            'optimizer': optimizer,\n                            'batch_size': batch_size,\n                            'epochs': epochs\n                        }\n\n# Train the best model using the best parameters\nbest_model = create_model(neurons=best_params['neurons'],\n                          activation=best_params['activation'],\n                          optimizer=best_params['optimizer'])\nbest_model.fit(X_train_scaled, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)\n\n# Evaluate the best model on test data\npredictions = best_model.predict(X_test_scaled)\nmse = mean_squared_error(y_test, predictions)\nr2 = r2_score(y_test, predictions)\nprint(f'Mean Squared Error: {mse}')\nprint(f'R-squared: {r2}')\nprint('Best Parameters:', best_params)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 504us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 503us/step\n\r 1/32 [..............................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 1ms/step\n\r 1/32 [..............................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 1ms/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 1ms/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 504us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 503us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 504us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 708us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 503us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 503us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 1ms/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 689us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 503us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 503us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 1ms/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 503us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 503us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 503us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 504us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 1ms/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 584us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 843us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 321us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 503us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 1ms/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 503us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 662us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 503us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 593us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 503us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 1ms/step\n\r 1/32 [..............................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 1ms/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 1ms/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 503us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 504us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 1ms/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 1ms/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 211us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 504us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 504us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 503us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 504us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 864us/step\n\r 1/32 [..............................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 1ms/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 504us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 504us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 504us/step\n\r 1/32 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 1ms/step\nMean Squared Error: 15682320765.157217\nR-squared: 0.8725350889627105\nBest Parameters: {'neurons': 128, 'activation': 'relu', 'optimizer': 'adam', 'batch_size': 32, 'epochs': 100}\n```\n:::\n:::\n\n\n::: {#cea97b25 .cell execution_count=26}\n``` {.python .cell-code}\n# Define the model\nmodel = SVR()\n\n# Define the parameters for GridSearchCV\nparam_grid = {\n    'C': [0.1, 1, 10, 100],  # Regularization parameter\n    'gamma': ['scale', 'auto'],  # Kernel coefficient\n    'kernel': ['linear', 'sigmoid']  # Type of kernel\n}\n\n# Create GridSearchCV\ngrid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1)\n\n# Perform grid search\ngrid_search.fit(X_train, y_train)\n\n# Print results\nprint(\"Best parameters found: \", grid_search.best_params_)\nprint(\"Best score found: \", grid_search.best_score_)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBest parameters found:  {'C': 100, 'gamma': 'scale', 'kernel': 'linear'}\nBest score found:  0.73778443791727\n```\n:::\n:::\n\n\n### Support Vector Regressor Model Evaluation\n\n::: {#40564ea3 .cell execution_count=27}\n``` {.python .cell-code}\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Get the best estimator\nbest_svr = grid_search.best_estimator_\n\n# Make predictions using the best model on the scaled test data\npredictions = best_svr.predict(X_test)\n\n# Calculate and print evaluation metrics\nmse = mean_squared_error(y_test, predictions)\nr2 = r2_score(y_test, predictions)\nprint(f'Mean Squared Error: {mse}')\nprint(f'R-squared: {r2}')\nprint('Best Parameters:', grid_search.best_params_)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMean Squared Error: 32693943451.0945\nR-squared: 0.7342656960115967\nBest Parameters: {'C': 100, 'gamma': 'scale', 'kernel': 'linear'}\n```\n:::\n:::\n\n\n::: {#7e9bc307 .cell execution_count=28}\n``` {.python .cell-code}\n#cross validation for model evaluation\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.svm import SVR\nimport numpy as np\n\nsvr_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\nprint(\"SVR Mean Squared Error:\", np.mean(svr_scores))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSVR Mean Squared Error: -124677012216.41104\n```\n:::\n:::\n\n\n::: {#1c3dacff .cell execution_count=29}\n``` {.python .cell-code}\n#plot actual and predicted values\nsns.scatterplot(x=y_test, y=predictions)\nplt.xlabel('True Values')\nplt.ylabel('Predicted Values')\n```\n\n::: {.cell-output .cell-output-display execution_count=29}\n```\nText(0, 0.5, 'Predicted Values')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](MineCrafters_files/figure-html/cell-30-output-2.png){width=597 height=443}\n:::\n:::\n\n\n### Random Forest Regressor\n\n::: {#5799ddb9 .cell execution_count=30}\n``` {.python .cell-code}\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\n\n# Define the parameter grid for hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [5, 10, 15, 20],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4]\n}\n\n# Initialize the Random Forest model\nrf = RandomForestRegressor(random_state=42)\n\n# Setup GridSearchCV\ngrid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n\n# Fit the model to the scaled training data\ngrid_search.fit(X_train, y_train)\n\n# Get the best estimator\nbest_rf = grid_search.best_estimator_\n```\n:::\n\n\n### Random Forest Model Evaluation\n\n::: {#2e65e964 .cell execution_count=31}\n``` {.python .cell-code}\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Make predictions using the best model on the scaled test data\npredictions = best_rf.predict(X_test)\n\n# Calculate and print evaluation metrics\nmse = mean_squared_error(y_test, predictions)\nr2 = r2_score(y_test, predictions)\nprint(f'Mean Squared Error: {mse}')\nprint(f'R-squared: {r2}')\nprint('Best Parameters:', grid_search.best_params_)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMean Squared Error: 14280727311.341614\nR-squared: 0.8839271518835241\nBest Parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n```\n:::\n:::\n\n\n::: {#807e68d1 .cell execution_count=32}\n``` {.python .cell-code}\n#cross validation for model evaluation\nrf_scores = cross_val_score(best_rf, X, y, cv=5, scoring='neg_mean_squared_error')\n\nprint(\"Random Forest Mean Squared Error:\", np.mean(rf_scores))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRandom Forest Mean Squared Error: -14504544972.249462\n```\n:::\n:::\n\n\n::: {#e62f6645 .cell execution_count=33}\n``` {.python .cell-code}\n#plot actual and predicted values\nsns.scatterplot(x=y_test, y=predictions)\nplt.xlabel('True Values')\nplt.ylabel('Predicted Values')\n```\n\n::: {.cell-output .cell-output-display execution_count=33}\n```\nText(0, 0.5, 'Predicted Values')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](MineCrafters_files/figure-html/cell-34-output-2.png){width=597 height=443}\n:::\n:::\n\n\n### XGBoost Regressor\n\n::: {#b910a0f7 .cell execution_count=34}\n``` {.python .cell-code}\n# Define the parameter grid\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [3, 6, 9],\n    'learning_rate': [0.01, 0.1, 0.2],\n    'subsample': [0.7, 0.8, 0.9],\n    'colsample_bytree': [0.7, 0.8, 0.9]\n}\n\n# Initialize XGBoost regressor\nxgb_reg = xgb.XGBRegressor(objective ='reg:squarederror', random_state=42)\n\n# Setup GridSearchCV\ngrid_search = GridSearchCV(estimator=xgb_reg, param_grid=param_grid, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n\n# Fit the model\ngrid_search.fit(X_train, y_train)\n\n# Get the best estimator\nbest_xgb = grid_search.best_estimator_\n```\n:::\n\n\n### XGBoost Regressor Model Evaluation\n\n::: {#ff4f7f16 .cell execution_count=35}\n``` {.python .cell-code}\n# Make predictions using the best model\npredictions = best_xgb.predict(X_test)\n\n# Calculate and print evaluation metrics\nmse = mean_squared_error(y_test, predictions)\nr2 = r2_score(y_test, predictions)\nprint(f'Mean Squared Error: {mse}')\nprint(f'R-squared: {r2}')\nprint('Best Parameters:', grid_search.best_params_)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMean Squared Error: 10946017250.64358\nR-squared: 0.9110314642864701\nBest Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8}\n```\n:::\n:::\n\n\n::: {#9ff85356 .cell execution_count=36}\n``` {.python .cell-code}\nrmse = np.sqrt(mse)\nmae = mean_absolute_error(y_test, predictions)\n\nprint(f'Root Mean Squared Error: {rmse}')\nprint(f'Mean Absolute Error: {mae}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRoot Mean Squared Error: 104623.21563899468\nMean Absolute Error: 83344.45606738135\n```\n:::\n:::\n\n\n::: {#78f3a8f5 .cell execution_count=37}\n``` {.python .cell-code}\n#cross validation for model evaluation\nxgb_scores = cross_val_score(best_xgb, X, y, cv=5, scoring='neg_mean_squared_error')\nprint(\"XGBoost Mean Squared Error:\", np.mean(xgb_scores))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nXGBoost Mean Squared Error: -11628096775.104847\n```\n:::\n:::\n\n\n::: {#478d01c3 .cell execution_count=38}\n``` {.python .cell-code}\n#plot actual and predicted values\nsns.scatterplot(x=y_test, y=predictions)\nplt.xlabel('True Values')\nplt.ylabel('Predicted Values')\n```\n\n::: {.cell-output .cell-output-display execution_count=38}\n```\nText(0, 0.5, 'Predicted Values')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](MineCrafters_files/figure-html/cell-39-output-2.png){width=597 height=443}\n:::\n:::\n\n\n### Elastic Net Model\n\n::: {#d58d4bd6 .cell execution_count=39}\n``` {.python .cell-code}\n# Standardize the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Define the Elastic Net model\nelastic_net = ElasticNet(random_state=42)\n\n# Define the grid of parameters to search\nparam_grid = {\n    'alpha': [0.1, 1, 10, 100],\n    'l1_ratio': [0.1, 0.5, 0.9]\n}\n\n# Setup GridSearchCV\ngrid_search = GridSearchCV(estimator=elastic_net, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n\n# Fit the model\ngrid_search.fit(X_train_scaled, y_train)\n\n# Get the best estimator\nbest_elastic_net = grid_search.best_estimator_\n\n# Make predictions\npredictions = best_elastic_net.predict(X_test_scaled)\n```\n:::\n\n\n### Elastic Net Model Evaluation\n\n::: {#46eed189 .cell execution_count=40}\n``` {.python .cell-code}\n# Calculate MSE\nmse = mean_squared_error(y_test, predictions)\nr2 = r2_score(y_test, predictions)\nprint(f'Mean Squared Error: {mse}')\nprint(f'R2 Score: {r2}')\nprint('Best Parameters:', grid_search.best_params_)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMean Squared Error: 10097788698.683523\nR2 Score: 0.9179258122936284\nBest Parameters: {'alpha': 0.1, 'l1_ratio': 0.9}\n```\n:::\n:::\n\n\n::: {#14ed31de .cell execution_count=41}\n``` {.python .cell-code}\n#cross validation for model evaluation\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n\nen_scores = cross_val_score(best_elastic_net, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\nprint(\"ElasticNet Mean Squared Error:\", np.mean(en_scores))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nElasticNet Mean Squared Error: -10277827255.660938\n```\n:::\n:::\n\n\n::: {#a66a3b36 .cell execution_count=42}\n``` {.python .cell-code}\n#plot actual and predicted values\nsns.scatterplot(x=y_test, y=predictions)\nplt.xlabel('True Values')\nplt.ylabel('Predicted Values')\n```\n\n::: {.cell-output .cell-output-display execution_count=42}\n```\nText(0, 0.5, 'Predicted Values')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](MineCrafters_files/figure-html/cell-43-output-2.png){width=589 height=443}\n:::\n:::\n\n\n## Discussion\n\n\n|    Model               |    R-squared Value    |\n|------------------------|-----------------------|\n| Neural Network         |    0.8714             |\n| Support Vector         |    0.7655             |\n| Random Forest          |    0.8839             |\n| XGBoost Regression     |    0.9105             |\n| Elastic Net Model      |    0.9179             |\n\n\nThe regression models exhibit varying degrees of predictive performance, with the Elastic Net model demonstrating the highest R-squared value (0.9179), closely followed by XGBoost Regression (0.9105), Random Forest Regression (0.8839), Neural Network (0.8714), and Support Vector Regression (0.7655).\n\nHence, the Elastic Net model could be considered for the prediction of the house prices.\n\n",
    "supporting": [
      "MineCrafters_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}