[
  {
    "objectID": "proposal.html",
    "href": "proposal.html",
    "title": "Brick-Metrics",
    "section": "",
    "text": "The primary objective of this project is to develop a predictive model for housing prices in the US.\nThis project centers around utilizing the USA_Housing dataset to build a predictive model for housing prices. The project aims to create a robust and accurate model that can estimate housing prices for given sets of input variables by employing regression algorithms. By leveraging machine learning techniques, the goal is to analyze the relationships between various features such as Average Area Income, Average Area House Age, Average Area of Rooms, Average Area of bedrooms, and Area Population, and predict the housing prices based on these factors.\nThrough exploratory data analysis, feature engineering, and machine learning modeling, the project will uncover patterns, correlations, and dependencies within the dataset. Subsequently, a regression model will be trained to understand and quantify the influence of each feature on the housing prices. The model’s performance will be evaluated using metrics such as mean squared error or R-squared, ensuring its reliability and accuracy."
  },
  {
    "objectID": "proposal.html#dataset",
    "href": "proposal.html#dataset",
    "title": "Brick-Metrics",
    "section": "Dataset",
    "text": "Dataset\n\n\nCode\n#&gt; Installing necessary libraries \n\nlibrary(tidyverse)\n\n#&gt; Loading the Dataset - solemate\n\nbrickMetrics &lt;- read.csv(\"data/USA_Housing.csv\")\n\n\nThe dataset comes from the Kaggle Database. The dataset consists of 5000 observations related to houses accross the United States with various features of information including their Average Area Income, Average Area House Age, Average Area Number of Rooms, Average Area Number of Bedrooms, Area Population,Address, and Price With this sizeable and diverse sample of housing data, this dataset promises to serve as a foundational resource for building the Brick-Metrics system. The table representing the features in the dataset and their description is presented below.\n\n\n\n\n\n\n\n\nFeature\nData Type\nDescription\n\n\n\n\nAvg. Area Income\nInteger\nAverage Area Income of the population in the specific location\n\n\nAvg. Area House Age\nInteger\nAverage Area House Age\n\n\nAvg. Area Number of Rooms\nInteger\nAverage Area of total Number of Rooms\n\n\nAverage Area Number of Rooms\nInteger\nAverage Area of total Number of Bedrooms\n\n\nArea Population\nInteger\nPopulation of the place\n\n\nAddress\nCharacter\nAddress of the house\n\n\nPrice\nInteger\nPrice of the house"
  },
  {
    "objectID": "proposal.html#question",
    "href": "proposal.html#question",
    "title": "Brick-Metrics",
    "section": "Question",
    "text": "Question\nHow accurately can the housing prices in the US be predicted?"
  },
  {
    "objectID": "proposal.html#analysis-plan",
    "href": "proposal.html#analysis-plan",
    "title": "Brick-Metrics",
    "section": "Analysis plan",
    "text": "Analysis plan\nBy following the below analysis plan, the project can efficiently implement a robust recommendation system that enhances the development of the prediction system.\n\nExploratory Data Analysis (EDA):\n\nAcquire and load the dataset.\nExplore the dataset to understand its structure and the variables it contains.\nVisualize data distributions, identify outliers, and check for missing values.\nAnalyze customer reviews and ratings to gain insights into user preferences.\n\nData Preprocessing:\n\nClean the data by addressing missing values and outliers.\nTransform categorical variables into numerical representations (e.g., one-hot encoding for brand, material, and style).\nSplit the data into training and testing sets for model evaluation.\n\nData Visualization\n\nVisualizing the necessary correlations.\n\nFeature Engineering:\n\nCreate additional features if necessary.\n\nTraining and Testing:\n\nSelect machine learning algorithms suitable for prediction like regression models.\nTrain multiple models on the training data.\nEvaluate model performance using testing data.\n\nModel Evaluation:\n\nUtilize metrics like Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and accuracy to assess each model’s performance.\nCompare the results to determine which models are the most effective in making recommendations.\n\nChoosing the Best Model:\n\nSelect the model with the lowest error or highest accuracy, depending on the chosen evaluation metric."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This project was developed by MineCrafters For INFO 523 - Data Mining and Discovery at the University of Arizona, taught by Dr. Greg Chism. The team is comprised of the following team members.\n\nAslam Sheik Dawood: Graduate student in Data Science, University of Arizona\nHari Dave: Graduate student in Data Science, University of Arizona\nPartha Koundinya P: Graduate student in Data Science, University of Arizona\nSarthak Miglani: Graduate student in Data Science, University of Arizona\nVinu Kevin Diesel: Graduate student in Data Science, University of Arizona"
  },
  {
    "objectID": "presentation.html",
    "href": "presentation.html",
    "title": "Project title",
    "section": "",
    "text": "The presentation is created using the Quarto CLI\n## sets the start of a new slide\n\n\n\n\nYou can use plain text\n\n\n\nor bullet points1\n\n\nor in two columns\n\n\n\nlike\nthis\n\n\n\n\n\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic       p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n1 (Intercept)   25.3      3.08        8.22 0.00000000358\n2 speed         -0.116    0.0642     -1.81 0.0806       \n\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    0.0983        0.0682  5.82      3.27  0.0806     1  -101.  207.  212.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\n\n\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSome text\ngoes here"
  },
  {
    "objectID": "presentation.html#quarto",
    "href": "presentation.html#quarto",
    "title": "Project title",
    "section": "",
    "text": "The presentation is created using the Quarto CLI\n## sets the start of a new slide"
  },
  {
    "objectID": "presentation.html#layouts",
    "href": "presentation.html#layouts",
    "title": "Project title",
    "section": "",
    "text": "You can use plain text\n\n\n\nor bullet points1\n\n\nor in two columns\n\n\n\nlike\nthis"
  },
  {
    "objectID": "presentation.html#code",
    "href": "presentation.html#code",
    "title": "Project title",
    "section": "",
    "text": "# A tibble: 2 × 5\n  term        estimate std.error statistic       p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n1 (Intercept)   25.3      3.08        8.22 0.00000000358\n2 speed         -0.116    0.0642     -1.81 0.0806       \n\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    0.0983        0.0682  5.82      3.27  0.0806     1  -101.  207.  212.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;"
  },
  {
    "objectID": "presentation.html#plots",
    "href": "presentation.html#plots",
    "title": "Project title",
    "section": "",
    "text": "Warning: Removed 2 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "presentation.html#plot-and-text",
    "href": "presentation.html#plot-and-text",
    "title": "Project title",
    "section": "",
    "text": "Some text\ngoes here"
  },
  {
    "objectID": "presentation.html#tables",
    "href": "presentation.html#tables",
    "title": "Project title",
    "section": "Tables",
    "text": "Tables\nIf you want to generate a table, make sure it is in the HTML format (instead of Markdown or other formats), e.g.,\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\n\n\n\n\nAdelie\nTorgersen\n39.1\n18.7\n181\n3750\nmale\n\n\nAdelie\nTorgersen\n39.5\n17.4\n186\n3800\nfemale\n\n\nAdelie\nTorgersen\n40.3\n18.0\n195\n3250\nfemale\n\n\nAdelie\nTorgersen\nNA\nNA\nNA\nNA\nNA\n\n\nAdelie\nTorgersen\n36.7\n19.3\n193\n3450\nfemale\n\n\nAdelie\nTorgersen\n39.3\n20.6\n190\n3650\nmale"
  },
  {
    "objectID": "presentation.html#images",
    "href": "presentation.html#images",
    "title": "Project title",
    "section": "Images",
    "text": "Images\n\n\n\nImage credit: Danielle Navarro, Percolate."
  },
  {
    "objectID": "presentation.html#math-expressions",
    "href": "presentation.html#math-expressions",
    "title": "Project title",
    "section": "Math Expressions",
    "text": "Math Expressions\nYou can write LaTeX math expressions inside a pair of dollar signs, e.g. $\\alpha+\\beta$ renders \\(\\alpha + \\beta\\). You can use the display style with double dollar signs:\n$$\\bar{X}=\\frac{1}{n}\\sum_{i=1}^nX_i$$\n\\[\n\\bar{X}=\\frac{1}{n}\\sum_{i=1}^nX_i\n\\]\nLimitations:\n\nThe source code of a LaTeX math expression must be in one line, unless it is inside a pair of double dollar signs, in which case the starting $$ must appear in the very beginning of a line, followed immediately by a non-space character, and the ending $$ must be at the end of a line, led by a non-space character;\nThere should not be spaces after the opening $ or before the closing $."
  },
  {
    "objectID": "presentation.html#feeling-adventurous",
    "href": "presentation.html#feeling-adventurous",
    "title": "Project title",
    "section": "Feeling adventurous?",
    "text": "Feeling adventurous?\n\nYou are welcomed to use the default styling of the slides. In fact, that’s what I expect majority of you will do. You will differentiate yourself with the content of your presentation.\nBut some of you might want to play around with slide styling. Some solutions for this can be found at https://quarto.org/docs/presentations/revealjs."
  },
  {
    "objectID": "presentation.html#footnotes",
    "href": "presentation.html#footnotes",
    "title": "Project title",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAnd add footnotes↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Brick-Metrics",
    "section": "",
    "text": "Add project abstract here."
  },
  {
    "objectID": "index.html#abstract",
    "href": "index.html#abstract",
    "title": "Brick-Metrics",
    "section": "",
    "text": "Add project abstract here."
  },
  {
    "objectID": "proposal.html#plan-of-attack",
    "href": "proposal.html#plan-of-attack",
    "title": "Brick-Metrics",
    "section": "Plan of Attack",
    "text": "Plan of Attack\n\n\n\n\n\n\n\n\nWeek\nWeekly Tasks\nTeam members involved\n\n\n\n\nTill November 8th\nExplore and finalize the dataset and the problem statements\nEveryone\n\n\n-\nComplete the proposal and assign some high-level tasks\nEveryone\n\n\nNov. 9th - 15th\nExploratory Data Analysis\nHari, Syed\n\n\n-\nData cleaning and Data pre-processing based on EDA\nPartha, Vinu, Sarthak\n\n\n-\nQuestion specific exploration and identify initial trends and patterns\nSarthak, Syed\n\n\nNov. 16th - 22nd\nData Preprocessing\nHari, Vinu\n\n\n-\nData Visualization\nPartha, Sarthak\n\n\nNov. 23rd - 29th\nFeature Engineering\nHari, Syed\n\n\n-\nTraining and Testing\nPartha, Vinu, Sarthak\n\n\nNov. 30th - December 6th\nRefining the code for code review with comments\nSarthak, Syed\n\n\n-\nModel Evaluation\nHari, Partha\n\n\nDec. 7th - 11th\nChoosing the Best Model\nEveryone\n\n\n-\nWrite-up and presentation for the project\nEveryone"
  },
  {
    "objectID": "proposal.html#repo-organization",
    "href": "proposal.html#repo-organization",
    "title": "Brick-Metrics",
    "section": "Repo Organization",
    "text": "Repo Organization\nThe following are the folders involved in the Project repository.\n\ndata/: Used for storing any necessary data files for the project, such as input files.\nimages/: Used for storing image files used in the project.\npresentation_files/: Folder for having presentation related files.\n_extra/: Used to brainstorm our analysis which won’t impact our project workflow.\n_freeze/: This folder is used to store the generated files during the build process. These files represent the frozen state of the website at a specific point in time.\n_site/: Folder used to store the generated static website files after the site generator processes the quarto document.\n.github/: Folder for storing github templates and workflow."
  },
  {
    "objectID": "proposal.html#project-objective",
    "href": "proposal.html#project-objective",
    "title": "Brick-Metrics",
    "section": "",
    "text": "The primary objective of this project is to develop a predictive model for housing prices in the US.\nThis project centers around utilizing the USA_Housing dataset to build a predictive model for housing prices. The project aims to create a robust and accurate model that can estimate housing prices for given sets of input variables by employing regression algorithms. By leveraging machine learning techniques, the goal is to analyze the relationships between various features such as Average Area Income, Average Area House Age, Average Area of Rooms, Average Area of bedrooms, and Area Population, and predict the housing prices based on these factors.\nThrough exploratory data analysis, feature engineering, and machine learning modeling, the project will uncover patterns, correlations, and dependencies within the dataset. Subsequently, a regression model will be trained to understand and quantify the influence of each feature on the housing prices. The model’s performance will be evaluated using metrics such as mean squared error or R-squared, ensuring its reliability and accuracy."
  }
]